{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "458458c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "978b2ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 5000\n",
      "Val size: 500\n",
      "Классов: 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TinyImageNetDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None, num_classes=10):\n",
    "        \"\"\"\n",
    "        root_dir: путь до папки tiny-imagenet-200\n",
    "        split: 'train', 'val' или 'test'\n",
    "        transform: трансформации изображений\n",
    "        num_classes: количество случайных классов для выборки\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Чтение всех классов\n",
    "        with open(os.path.join(root_dir, 'wnids.txt'), 'r') as f:\n",
    "            self.class_names = [line.strip() for line in f]\n",
    "\n",
    "        # Выбираем случайные 10 классов\n",
    "        self.selected_classes = random.sample(self.class_names, self.num_classes)\n",
    "        self.class_to_idx = {name: i for i, name in enumerate(self.selected_classes)}\n",
    "\n",
    "        self.samples = []\n",
    "        if split == 'train':\n",
    "            train_dir = os.path.join(root_dir, 'train')\n",
    "            for cls in self.selected_classes:\n",
    "                img_dir = os.path.join(train_dir, cls, 'images')\n",
    "                if not os.path.exists(img_dir):\n",
    "                    continue\n",
    "                for img_name in os.listdir(img_dir):\n",
    "                    img_path = os.path.join(img_dir, img_name)\n",
    "                    label = self.class_to_idx[cls]\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        elif split == 'val':\n",
    "            val_dir = os.path.join(root_dir, 'val', 'images')\n",
    "            anno_path = os.path.join(root_dir, 'val', 'val_annotations.txt')\n",
    "\n",
    "            label_map = {}\n",
    "            with open(anno_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    img_name, cls, *_ = line.strip().split('\\t')\n",
    "                    label_map[img_name] = cls\n",
    "\n",
    "            for img_name in os.listdir(val_dir):\n",
    "                cls = label_map.get(img_name)\n",
    "                if cls in self.selected_classes:\n",
    "                    img_path = os.path.join(val_dir, img_name)\n",
    "                    label = self.class_to_idx[cls]\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        else:  # Test\n",
    "            test_dir = os.path.join(root_dir, 'test', 'images')\n",
    "            for img_name in os.listdir(test_dir):\n",
    "                img_path = os.path.join(test_dir, img_name)\n",
    "                self.samples.append((img_path, -1))  # тест без меток\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((72, 72)),\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "root = \"tiny-imagenet-200\"\n",
    "\n",
    "# Обучающий и валидационный датасеты\n",
    "train_dataset = TinyImageNetDataset(root, split='train', transform=train_transform)\n",
    "val_dataset = TinyImageNetDataset(root, split='val', transform=val_transform)\n",
    "\n",
    "# Загрузчики данных\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "# Вывод статистики\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "print(f\"Классов: {len(train_dataset.selected_classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdf0ec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выбранные классы:\n",
      "n03444034: n03444034\tgo-kart\n",
      "n07614500: n07614500\tice cream, icecream\n",
      "n02802426: n02802426\tbasketball\n",
      "n02788148: n02788148\tbannister, banister, balustrade, balusters, handrail\n",
      "n02988304: n02988304\tCD player\n",
      "n04456115: n04456115\ttorch\n",
      "n02481823: n02481823\tchimpanzee, chimp, Pan troglodytes\n",
      "n02058221: n02058221\talbatross, mollymawk\n",
      "n07720875: n07720875\tbell pepper\n",
      "n03085013: n03085013\tcomputer keyboard, keypad\n"
     ]
    }
   ],
   "source": [
    "def print_cls_names(root_dir):\n",
    "    print(\"Выбранные классы:\")\n",
    "    with open(os.path.join(root_dir, 'words.txt'), 'r') as f:\n",
    "        words_strings = [line.strip() for line in f]\n",
    "        for cls in train_dataset.selected_classes:\n",
    "            for line in words_strings:\n",
    "                if line.startswith(cls):\n",
    "                    print(f\"{cls}: {line}\")\n",
    "                    break\n",
    "print_cls_names(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b00c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cls_name_from_code(root_dir,code_name):\n",
    "    print(\"Название класса:\")\n",
    "    with open(os.path.join(root_dir, 'words.txt'), 'r') as f:\n",
    "        words_strings = [line.strip() for line in f]\n",
    "        for line in words_strings:\n",
    "            if line.startswith(code_name):\n",
    "                print(f\"{line}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# import time\n",
    "\n",
    "# timeout = 60  # Максимальное время ожидания в секундах\n",
    "# start_time = time.time()\n",
    "\n",
    "# while time.time() - start_time < timeout:\n",
    "#     try:\n",
    "#         images, labels = next(iter(train_loader))\n",
    "#         break  \n",
    "#     except StopIteration:\n",
    "#         print(\"Ошибка в загрузке данных или итерации\")\n",
    "#         break\n",
    "#     if time.time() - start_time > timeout:\n",
    "#         print(\"Превышено время ожидания. Прерываю выполнение.\")\n",
    "#         break\n",
    "\n",
    "# def denormalize(img_tensor):\n",
    "#     \"\"\"Вернём изображение из нормализованного диапазона в [0,1]\"\"\"\n",
    "#     mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n",
    "#     std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n",
    "#     img = img_tensor.permute(1, 2, 0) * std + mean\n",
    "#     return img.clamp(0, 1)\n",
    "\n",
    "# images_vis = images.permute(0, 2, 3, 1)\n",
    "\n",
    "# images_vis = torch.stack([denormalize(img) for img in images])\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(8):\n",
    "#     plt.subplot(2, 4, i+1)\n",
    "#     plt.imshow(images_vis[i])\n",
    "#     plt.title(f\"Class: {labels[i].item()}\")\n",
    "#     plt.axis('off')\n",
    "# plt.suptitle(\"Примеры изображений из Tiny ImageNet (с аугментациями)\", fontsize=16)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Размер батча: {images.shape}\")\n",
    "# print(f\"Диапазон значений: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "# print(f\"Метки классов: {labels.tolist()}\")\n",
    "# print(f\"Всего классов в датасете: {len(train_dataset.class_names)}\")\n",
    "# print(f\"Примеры названий классов: {train_dataset.class_names[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab3e61f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер изображения: torch.Size([1, 3, 64, 64])\n",
      "Метка класса: 2\n",
      "Название класса:\n",
      "n03255030\tdumbbell\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Преобразования\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Изменяем размер изображения\n",
    "    transforms.ToTensor(),        # Преобразуем изображение в тензор\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Нормализуем\n",
    "])\n",
    "\n",
    "# Инициализация датасета и DataLoader\n",
    "root = \"tiny-imagenet-200\"\n",
    "train_dataset = TinyImageNetDataset(root, split='train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)  # Установим batch_size=1\n",
    "\n",
    "# Получаем одно изображение и метку\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Денормализация для отображения\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n",
    "    img = img_tensor.permute(1, 2, 0) * std + mean\n",
    "    return img.clamp(0, 1)\n",
    "\n",
    "# Денормализуем изображение\n",
    "img_vis = denormalize(images[0])\n",
    "\n",
    "# Визуализация одного изображения\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_vis.numpy())  # Переходим от тензора к NumPy для matplotlib\n",
    "class_name = train_dataset.selected_classes[labels.item()]  # Получаем имя класса по индексу\n",
    "plt.title(f\"Class: {class_name}\")  # Печатаем название класса\n",
    "plt.axis('off')  # Убираем оси\n",
    "plt.show()\n",
    "\n",
    "print(f\"Размер изображения: {images.shape}\")\n",
    "print(f\"Метка класса: {labels.item()}\")  # Выводим индекс метки\n",
    "print_cls_name_from_code(root,class_name)  # Выводим название класса\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6e62234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Метод 1: Простая случайная стратификация\n",
      " Всего образцов: 5000\n",
      " Случайное разделение:\n",
      "   Train: 4000 образцов\n",
      "   Val: 1000 образцов\n",
      " Случайное train - распределение классов:\n",
      "   Минимум: 388\n",
      "   Максимум: 418\n",
      "   Среднее: 400.0\n",
      "   Стандартное отклонение: 9.5\n",
      " Случайное val - распределение классов:\n",
      "   Минимум: 82\n",
      "   Максимум: 112\n",
      "   Среднее: 100.0\n",
      "   Стандартное отклонение: 9.5\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "print(\" Метод 1: Простая случайная стратификация\")\n",
    "\n",
    "train_dataset = TinyImageNetDataset(root, split='train', transform=train_transform)\n",
    "all_samples = train_dataset.samples\n",
    "\n",
    "print(f\" Всего образцов: {len(all_samples)}\")\n",
    "\n",
    "random.seed(42)\n",
    "all_samples_copy = all_samples.copy()\n",
    "random.shuffle(all_samples_copy)\n",
    "\n",
    "val_fraction = 0.2\n",
    "split_idx = int(len(all_samples_copy) * (1 - val_fraction))\n",
    "train_split_random = all_samples_copy[:split_idx]\n",
    "val_split_random = all_samples_copy[split_idx:]\n",
    "\n",
    "print(f\" Случайное разделение:\")\n",
    "print(f\"   Train: {len(train_split_random)} образцов\")\n",
    "print(f\"   Val: {len(val_split_random)} образцов\")\n",
    "\n",
    "def analyze_class_distribution(samples, name):\n",
    "    labels = [label for _, label in samples]\n",
    "    class_counts = Counter(labels)\n",
    "    print(f\" {name} - распределение классов:\")\n",
    "    print(f\"   Минимум: {min(class_counts.values())}\")\n",
    "    print(f\"   Максимум: {max(class_counts.values())}\")\n",
    "    print(f\"   Среднее: {np.mean(list(class_counts.values())):.1f}\")\n",
    "    print(f\"   Стандартное отклонение: {np.std(list(class_counts.values())):.1f}\")\n",
    "\n",
    "analyze_class_distribution(train_split_random, \"Случайное train\")\n",
    "analyze_class_distribution(val_split_random, \"Случайное val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd377d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполните пропуски в BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Базовый блок ResNet с residual connection\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): количество входных каналов\n",
    "        out_channels (int): количество выходных каналов\n",
    "        stride (int): шаг свертки (по умолчанию 1)\n",
    "        downsample (nn.Module): слой для изменения размерности (если нужно)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = downsample\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        idenity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Вторая свертка\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out) \n",
    "\n",
    "        if self.downsample is not None:\n",
    "            idenity = self.downsample(x)\n",
    "\n",
    "        out += idenity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# basic_block = BasicBlock(64, 64, stride=2, downsample=nn.Sequential(\n",
    "#     nn.Conv2d(64, 64, kernel_size=1, stride=2),\n",
    "#     nn.BatchNorm2d(64)\n",
    "# ))\n",
    "\n",
    "# # Тестовый вход: 2 изображения размером 64x32x32\n",
    "# test_input = torch.randn(2, 64, 32, 32)\n",
    "\n",
    "# # Применяем блок\n",
    "# output = basic_block(test_input)\n",
    "# print(output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96eb7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64  # Инициализируем in_channels\n",
    "        \n",
    "        # Первый слой: Conv2d + BatchNorm + ReLU + MaxPool\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Layer1: 2x Basic Block с 64 каналами\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "\n",
    "        # Layer2: 2x Basic Block с 128 каналами\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "\n",
    "        # Layer3: 2x Basic Block с 256 каналами\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "\n",
    "        # Layer4: 2x Basic Block с 512 каналами\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Полносвязный слой для классификации (10 классов)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d02a53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант A: 32 -> 64 -> 128 -> 256\n",
    "class ResNet18_A(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(32, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        layers = [BasicBlock(self.in_channels, out_channels, stride, downsample)]\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Вариант B: 64 -> 128 -> 256 (без 4-го слоя)\n",
    "class ResNet18_B(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        layers = [BasicBlock(self.in_channels, out_channels, stride, downsample)]\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3b2c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def validate_epoch(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeda72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, num_epochs, device, plotting=False):\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        # Сохраняем метрики для графиков\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Логирование\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')  # Сохранение модели\n",
    "\n",
    "    # Построение графиков\n",
    "    if not plotting:\n",
    "        plot_metrics(train_accuracies, val_accuracies, train_losses, val_losses)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "def plot_metrics(train_accuracies, val_accuracies, train_losses, val_losses):\n",
    "    epochs = range(1, len(train_accuracies) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, label='Val Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Val Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "353414fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_info(model):\n",
    "    # Количество параметров\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "    # Архитектура модели\n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28ad08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2_models_metrics(model_A, model_B):\n",
    "    # Here, we assume that train_loss, val_loss, train_accuracy, and val_accuracy \n",
    "    # are stored from the training process in the respective model objects.\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plt.subplot(2, 4, 1)\n",
    "    plt.plot(model_A.train_loss, label=\"Model A Train Loss\")\n",
    "    plt.plot(model_B.train_loss, label=\"Model B Train Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plt.subplot(2, 4, 2)\n",
    "    plt.plot(model_A.val_loss, label=\"Model A Validation Loss\")\n",
    "    plt.plot(model_B.val_loss, label=\"Model B Validation Loss\")\n",
    "    plt.title(\"Validation Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training Accuracy\n",
    "    plt.subplot(2, 4, 3)\n",
    "    plt.plot(model_A.train_accuracy, label=\"Model A Train Accuracy\")\n",
    "    plt.plot(model_B.train_accuracy, label=\"Model B Train Accuracy\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Validation Accuracy\n",
    "    plt.subplot(2, 4, 4)\n",
    "    plt.plot(model_A.val_accuracy, label=\"Model A Validation Accuracy\")\n",
    "    plt.plot(model_B.val_accuracy, label=\"Model B Validation Accuracy\")\n",
    "    plt.title(\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fddc6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_and_compare_models(train_loader, val_loader, num_classes=10, epochs=20):\n",
    "    # Create both models\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_A = ResNet18_A(num_classes=num_classes).to(device)\n",
    "    model_B = ResNet18_B(num_classes=num_classes).to(device)\n",
    "    \n",
    "    # Define optimizers and loss functions\n",
    "    optimizer_A = optim.Adam(model_A.parameters(), lr=0.001)\n",
    "    optimizer_B = optim.Adam(model_B.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train models\n",
    "    train_and_evaluate(model_A, train_loader, val_loader, optimizer_A, criterion, num_epochs=epochs, device=device, plotting=True)\n",
    "    train_and_evaluate(model_B, train_loader, val_loader, optimizer_B, criterion, num_epochs=epochs, device=device, plotting=True)\n",
    "    \n",
    "    # Print model comparison results\n",
    "    print(f\"Model A - Number of parameters: {sum(p.numel() for p in model_A.parameters())}\")\n",
    "    print(f\"Model B - Number of parameters: {sum(p.numel() for p in model_B.parameters())}\")\n",
    "    \n",
    "    # Plot metrics for both models\n",
    "    plot_2_models_metrics(model_A, model_B)\n",
    "    \n",
    "    return model_A, model_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6531c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE RESNET18\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Модель, оптимизатор и loss функция\n",
    "model = ResNet18(num_classes=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Обучение и валидация\n",
    "train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, num_epochs=20, device=device)\n",
    "\n",
    "# Вывод информации о модели\n",
    "print_model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13e4955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 2.3679, Train Accuracy: 0.1320\n",
      "Val Loss: 2.3557, Val Accuracy: 0.1140\n",
      "Epoch 2/20\n",
      "Train Loss: 2.1764, Train Accuracy: 0.2066\n",
      "Val Loss: 2.5160, Val Accuracy: 0.0880\n",
      "Epoch 3/20\n",
      "Train Loss: 1.9764, Train Accuracy: 0.2932\n",
      "Val Loss: 2.4631, Val Accuracy: 0.1020\n",
      "Epoch 4/20\n",
      "Train Loss: 1.8277, Train Accuracy: 0.3620\n",
      "Val Loss: 2.5372, Val Accuracy: 0.1020\n",
      "Epoch 5/20\n",
      "Train Loss: 1.6642, Train Accuracy: 0.4128\n",
      "Val Loss: 2.6683, Val Accuracy: 0.1080\n",
      "Epoch 6/20\n",
      "Train Loss: 1.4989, Train Accuracy: 0.4764\n",
      "Val Loss: 2.7364, Val Accuracy: 0.1200\n",
      "Epoch 7/20\n",
      "Train Loss: 1.2851, Train Accuracy: 0.5560\n",
      "Val Loss: 3.3308, Val Accuracy: 0.0980\n",
      "Epoch 8/20\n",
      "Train Loss: 1.0529, Train Accuracy: 0.6374\n",
      "Val Loss: 3.2043, Val Accuracy: 0.1200\n",
      "Epoch 9/20\n",
      "Train Loss: 0.7955, Train Accuracy: 0.7312\n",
      "Val Loss: 4.6015, Val Accuracy: 0.0880\n",
      "Epoch 10/20\n",
      "Train Loss: 0.5217, Train Accuracy: 0.8350\n",
      "Val Loss: 5.0323, Val Accuracy: 0.1660\n",
      "Epoch 11/20\n",
      "Train Loss: 0.3581, Train Accuracy: 0.8802\n",
      "Val Loss: 6.1899, Val Accuracy: 0.0980\n",
      "Epoch 12/20\n",
      "Train Loss: 0.2377, Train Accuracy: 0.9216\n",
      "Val Loss: 6.5196, Val Accuracy: 0.1420\n",
      "Epoch 13/20\n",
      "Train Loss: 0.1956, Train Accuracy: 0.9364\n",
      "Val Loss: 8.2457, Val Accuracy: 0.1180\n",
      "Epoch 14/20\n",
      "Train Loss: 0.1592, Train Accuracy: 0.9494\n",
      "Val Loss: 6.9392, Val Accuracy: 0.1400\n",
      "Epoch 15/20\n",
      "Train Loss: 0.1406, Train Accuracy: 0.9518\n",
      "Val Loss: 5.5842, Val Accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "Train Loss: 0.1216, Train Accuracy: 0.9606\n",
      "Val Loss: 7.4798, Val Accuracy: 0.1220\n",
      "Epoch 17/20\n",
      "Train Loss: 0.1311, Train Accuracy: 0.9562\n",
      "Val Loss: 8.7946, Val Accuracy: 0.0960\n",
      "Epoch 18/20\n",
      "Train Loss: 0.1163, Train Accuracy: 0.9598\n",
      "Val Loss: 10.1367, Val Accuracy: 0.1140\n",
      "Epoch 19/20\n",
      "Train Loss: 0.1079, Train Accuracy: 0.9642\n",
      "Val Loss: 10.5591, Val Accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "Train Loss: 0.0978, Train Accuracy: 0.9674\n",
      "Val Loss: 10.4365, Val Accuracy: 0.1380\n",
      "Training complete.\n",
      "Epoch 1/20\n",
      "Train Loss: 2.3151, Train Accuracy: 0.1450\n",
      "Val Loss: 2.4666, Val Accuracy: 0.1440\n",
      "Epoch 2/20\n",
      "Train Loss: 2.0885, Train Accuracy: 0.2522\n",
      "Val Loss: 2.3784, Val Accuracy: 0.0960\n",
      "Epoch 3/20\n",
      "Train Loss: 1.8687, Train Accuracy: 0.3490\n",
      "Val Loss: 2.8305, Val Accuracy: 0.1260\n",
      "Epoch 4/20\n",
      "Train Loss: 1.6635, Train Accuracy: 0.4256\n",
      "Val Loss: 3.1951, Val Accuracy: 0.0660\n",
      "Epoch 5/20\n",
      "Train Loss: 1.4095, Train Accuracy: 0.5190\n",
      "Val Loss: 3.6066, Val Accuracy: 0.0900\n",
      "Epoch 6/20\n",
      "Train Loss: 1.1013, Train Accuracy: 0.6272\n",
      "Val Loss: 3.9376, Val Accuracy: 0.0840\n",
      "Epoch 7/20\n",
      "Train Loss: 0.7302, Train Accuracy: 0.7718\n",
      "Val Loss: 5.8134, Val Accuracy: 0.0640\n",
      "Epoch 8/20\n",
      "Train Loss: 0.3567, Train Accuracy: 0.9140\n",
      "Val Loss: 6.2690, Val Accuracy: 0.0820\n",
      "Epoch 9/20\n",
      "Train Loss: 0.1313, Train Accuracy: 0.9796\n",
      "Val Loss: 10.0596, Val Accuracy: 0.0660\n",
      "Epoch 10/20\n",
      "Train Loss: 0.0835, Train Accuracy: 0.9836\n",
      "Val Loss: 9.6085, Val Accuracy: 0.0820\n",
      "Epoch 11/20\n",
      "Train Loss: 0.0469, Train Accuracy: 0.9932\n",
      "Val Loss: 12.1807, Val Accuracy: 0.0720\n",
      "Epoch 12/20\n",
      "Train Loss: 0.0510, Train Accuracy: 0.9894\n",
      "Val Loss: 13.4544, Val Accuracy: 0.0600\n",
      "Epoch 13/20\n",
      "Train Loss: 0.0442, Train Accuracy: 0.9884\n",
      "Val Loss: 14.0125, Val Accuracy: 0.0860\n",
      "Epoch 14/20\n",
      "Train Loss: 0.0421, Train Accuracy: 0.9908\n",
      "Val Loss: 14.5569, Val Accuracy: 0.0660\n",
      "Epoch 15/20\n",
      "Train Loss: 0.0376, Train Accuracy: 0.9908\n",
      "Val Loss: 12.5172, Val Accuracy: 0.0680\n",
      "Epoch 16/20\n",
      "Train Loss: 0.0327, Train Accuracy: 0.9900\n",
      "Val Loss: 14.9540, Val Accuracy: 0.0940\n",
      "Epoch 17/20\n",
      "Train Loss: 0.0260, Train Accuracy: 0.9954\n",
      "Val Loss: 10.4567, Val Accuracy: 0.0900\n",
      "Epoch 18/20\n",
      "Train Loss: 0.0317, Train Accuracy: 0.9928\n",
      "Val Loss: 14.0207, Val Accuracy: 0.0860\n",
      "Epoch 19/20\n",
      "Train Loss: 0.0282, Train Accuracy: 0.9926\n",
      "Val Loss: 10.5644, Val Accuracy: 0.0840\n",
      "Epoch 20/20\n",
      "Train Loss: 0.0238, Train Accuracy: 0.9946\n",
      "Val Loss: 16.7924, Val Accuracy: 0.0780\n",
      "Training complete.\n",
      "Model A - Number of parameters: 2803850\n",
      "Model B - Number of parameters: 2787594\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ResNet18_A' object has no attribute 'train_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model_A, model_B = \u001b[43mtrain_and_compare_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain_and_compare_models\u001b[39m\u001b[34m(train_loader, val_loader, num_classes, epochs)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel B - Number of parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel_B.parameters())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Plot metrics for both models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mplot_2_models_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_B\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_A, model_B\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mplot_2_models_metrics\u001b[39m\u001b[34m(model_A, model_B)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Plot Training Loss\u001b[39;00m\n\u001b[32m      7\u001b[39m plt.subplot(\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m plt.plot(\u001b[43mmodel_A\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_loss\u001b[49m, label=\u001b[33m\"\u001b[39m\u001b[33mModel A Train Loss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m plt.plot(model_B.train_loss, label=\u001b[33m\"\u001b[39m\u001b[33mModel B Train Loss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Stasy\\Desktop\\учёба\\AI_Architecture\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1928\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1926\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1929\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'ResNet18_A' object has no attribute 'train_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_A, model_B = train_and_compare_models(train_loader, val_loader, num_classes=10, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
