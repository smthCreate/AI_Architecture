{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–µ–º–∏–Ω–∞—Ä 2: –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–∏—Å–∫ –æ—à–∏–±–æ–∫ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–æ–¥–µ–ª—å 1\n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.drop1 = nn.Dropout2d(0.5)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.fc = nn.Linear(128 * 8 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.drop1(self.bn1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# model1 = CNN1()\n",
    "# test_input = torch.randn(1, 3, 64, 64)\n",
    "# output = model1(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–æ–¥–µ–ª—å 2\n",
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model2 = CNN2()\n",
    "test_input = torch.randn(1, 3, 64, 64)\n",
    "output = model2(test_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.branch2 = nn.Conv2d(3, 128, 5, padding=2)\n",
    "        self.fc = nn.Linear(192 * 16 * 16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.branch1(x))\n",
    "        b2 = F.relu(self.branch2(x))\n",
    "        out = torch.cat([b1, b2], dim=0)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "model3 = CNN3()\n",
    "test_input = torch.randn(1, 3, 64, 64)\n",
    "output = model3(test_input)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ DataLoader\n",
    "\n",
    "\n",
    "### –ß—Ç–æ —Ç–∞–∫–æ–µ Dataset?\n",
    "- **Dataset** - —ç—Ç–æ –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö\n",
    "- **DataLoader** - —ç—Ç–æ –∏—Ç–µ—Ä–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –±–∞—Ç—á–∏ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É\n",
    "\n",
    "### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã Dataset:\n",
    "- `__init__()` - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, –∑–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n",
    "- `__len__()` - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "- `__getitem__(idx)` - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –ø–æ –∏–Ω–¥–µ–∫—Å—É\n",
    "\n",
    "** –°–æ–∑–¥–∞–¥–∏–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π DataLoader –¥–ª—è Tiny ImageNet:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TinyImageNetDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: –ø—É—Ç—å –¥–æ –ø–∞–ø–∫–∏ tiny-imagenet-200\n",
    "        split: 'train', 'val' –∏–ª–∏ 'test'\n",
    "        transform: —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(os.path.join(root_dir, 'wnids.txt'), 'r') as f:\n",
    "            self.class_names = [line.strip() for line in f]\n",
    "        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
    "\n",
    "        self.samples = []\n",
    "        if split == 'train':\n",
    "            train_dir = os.path.join(root_dir, 'train')\n",
    "            for cls in os.listdir(train_dir):\n",
    "                img_dir = os.path.join(train_dir, cls, 'images')\n",
    "                if not os.path.exists(img_dir):\n",
    "                    continue\n",
    "                for img_name in os.listdir(img_dir):\n",
    "                    img_path = os.path.join(img_dir, img_name)\n",
    "                    label = self.class_to_idx[cls]\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        elif split == 'val':\n",
    "            val_dir = os.path.join(root_dir, 'val', 'images')\n",
    "            anno_path = os.path.join(root_dir, 'val', 'val_annotations.txt')\n",
    "\n",
    "            label_map = {}\n",
    "            with open(anno_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    img_name, cls, *_ = line.strip().split('\\t')\n",
    "                    label_map[img_name] = cls\n",
    "\n",
    "            for img_name in os.listdir(val_dir):\n",
    "                cls = label_map.get(img_name)\n",
    "                if cls:\n",
    "                    img_path = os.path.join(val_dir, img_name)\n",
    "                    label = self.class_to_idx[cls]\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        else:\n",
    "            test_dir = os.path.join(root_dir, 'test', 'images')\n",
    "            for img_name in os.listdir(test_dir):\n",
    "                img_path = os.path.join(test_dir, img_name)\n",
    "                self.samples.append((img_path, -1))  # —Ç–µ—Å—Ç –±–µ–∑ –º–µ—Ç–æ–∫\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((72, 72)),                    \n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),  \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),                     \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "root = \"data/tiny-imagenet-200\"\n",
    "\n",
    "train_dataset = TinyImageNetDataset(root, split='train', transform=train_transform)\n",
    "val_dataset = TinyImageNetDataset(root, split='val', transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "print(f\"–ö–ª–∞—Å—Å–æ–≤: {len(train_dataset.class_names)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    \"\"\"–í–µ—Ä–Ω—ë–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≤ [0,1]\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n",
    "    img = img_tensor.permute(1, 2, 0) * std + mean\n",
    "    return img.clamp(0, 1)\n",
    "\n",
    "images_vis = images.permute(0, 2, 3, 1)\n",
    "\n",
    "images_vis = torch.stack([denormalize(img) for img in images])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(images_vis[i])\n",
    "    plt.title(f\"Class: {labels[i].item()}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"–ü—Ä–∏–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ Tiny ImageNet (—Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {images.shape}\")\n",
    "print(f\"–î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "print(f\"–ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤: {labels.tolist()}\")\n",
    "print(f\"–í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: {len(train_dataset.class_names)}\")\n",
    "print(f\"–ü—Ä–∏–º–µ—Ä—ã –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤: {train_dataset.class_names[:5]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "### –ß—Ç–æ —Ç–∞–∫–æ–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è?\n",
    "**–°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è** - —ç—Ç–æ –º–µ—Ç–æ–¥ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏.\n",
    "\n",
    "###  –ó–∞—á–µ–º –Ω—É–∂–Ω–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è?\n",
    "- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –º–µ–∂–¥—É train/val/test\n",
    "- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö –∫–ª–∞—Å—Å–∞—Ö\n",
    "- –î–∞–µ—Ç –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "###  –¢–∏–ø—ã —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n",
    "1. **–°–ª—É—á–∞–π–Ω–∞—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è** - –ø—Ä–æ—Å—Ç–æ–µ —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ\n",
    "2. **K-Fold —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è** - —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ k —á–∞—Å—Ç–µ–π\n",
    "3. **–°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —ç–º–±–µ–¥–∏–Ω–≥–∞–º** - —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "** –†–∞—Å—Å–º–æ—Ç—Ä–∏–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã:**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ú–µ—Ç–æ–¥ 1: –ü—Ä–æ—Å—Ç–∞—è —Å–ª—É—á–∞–π–Ω–∞—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" –ú–µ—Ç–æ–¥ 1: –ü—Ä–æ—Å—Ç–∞—è —Å–ª—É—á–∞–π–Ω–∞—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è\")\n",
    "\n",
    "train_dataset = TinyImageNetDataset(root, split='train', transform=train_transform)\n",
    "all_samples = train_dataset.samples\n",
    "\n",
    "print(f\" –í—Å–µ–≥–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(all_samples)}\")\n",
    "\n",
    "random.seed(42)\n",
    "all_samples_copy = all_samples.copy()\n",
    "random.shuffle(all_samples_copy)\n",
    "\n",
    "val_fraction = 0.2\n",
    "split_idx = int(len(all_samples_copy) * (1 - val_fraction))\n",
    "train_split_random = all_samples_copy[:split_idx]\n",
    "val_split_random = all_samples_copy[split_idx:]\n",
    "\n",
    "print(f\" –°–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ:\")\n",
    "print(f\"   Train: {len(train_split_random)} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
    "print(f\"   Val: {len(val_split_random)} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
    "\n",
    "def analyze_class_distribution(samples, name):\n",
    "    labels = [label for _, label in samples]\n",
    "    class_counts = Counter(labels)\n",
    "    print(f\" {name} - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:\")\n",
    "    print(f\"   –ú–∏–Ω–∏–º—É–º: {min(class_counts.values())}\")\n",
    "    print(f\"   –ú–∞–∫—Å–∏–º—É–º: {max(class_counts.values())}\")\n",
    "    print(f\"   –°—Ä–µ–¥–Ω–µ–µ: {np.mean(list(class_counts.values())):.1f}\")\n",
    "    print(f\"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {np.std(list(class_counts.values())):.1f}\")\n",
    "\n",
    "analyze_class_distribution(train_split_random, \"–°–ª—É—á–∞–π–Ω–æ–µ train\")\n",
    "analyze_class_distribution(val_split_random, \"–°–ª—É—á–∞–π–Ω–æ–µ val\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ú–µ—Ç–æ–¥ 2: C—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = [x for x, y in all_samples]  # –ø—É—Ç–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º\n",
    "y = [y for x, y in all_samples]  # –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤\n",
    "\n",
    "print(f\" –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(X)} –æ–±—Ä–∞–∑—Ü–æ–≤ —Å {len(set(y))} –∫–ª–∞—Å—Å–∞–º–∏\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=val_fraction, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(X, y))\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è\n",
    "train_split_stratified = [all_samples[i] for i in train_idx]\n",
    "val_split_stratified = [all_samples[i] for i in val_idx]\n",
    "\n",
    "print(f\" –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ:\")\n",
    "print(f\"   Train: {len(train_split_stratified)} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
    "print(f\"   Val: {len(val_split_stratified)} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤\n",
    "analyze_class_distribution(train_split_stratified, \"–°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ train\")\n",
    "analyze_class_distribution(val_split_stratified, \"–°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ val\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ú–µ—Ç–æ–¥ 3: K-Fold —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\" –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ {k} —Ñ–æ–ª–¥–æ–≤:\")\n",
    "fold_splits = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    train_split = [all_samples[i] for i in train_idx]\n",
    "    val_split = [all_samples[i] for i in val_idx]\n",
    "    fold_splits.append((train_split, val_split))\n",
    "    print(f\"   Fold {fold}: train={len(train_split)}, val={len(val_split)}\")\n",
    "\n",
    "print(f\" –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Ñ–æ–ª–¥–∞:\")\n",
    "analyze_class_distribution(fold_splits[0][0], \"Fold 0 train\")\n",
    "analyze_class_distribution(fold_splits[0][1], \"Fold 0 val\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–∏–Ω–≥–∏\n",
    "\n",
    "## –ß—Ç–æ —Ç–∞–∫–æ–µ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–∏–Ω–≥–∏?\n",
    "–í–º–µ—Å—Ç–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º, –º—ã –º–æ–∂–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ **—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º** (—ç–º–±–µ–¥–∏–Ω–≥–∞–º), –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n",
    "\n",
    "### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n",
    "- –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "- –ú–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ —Å–∫—Ä—ã—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "- –ü–æ–ª–µ–∑–Ω–æ –∫–æ–≥–¥–∞ –∫–ª–∞—Å—Å—ã –Ω–µ–æ–¥–Ω–æ—Ä–æ–¥–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Å–µ–±—è\n",
    "\n",
    "### –ê–ª–≥–æ—Ä–∏—Ç–º:\n",
    "1. –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "2. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ (K-means)\n",
    "3. –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –®–∞–≥ 1: –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "\n",
    "–î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑—å–º–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–æ–≤, —á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_classes = [0, 5, 10, 15, 20]  # 5 –∫–ª–∞—Å—Å–æ–≤\n",
    "subset_samples = [s for s in train_dataset.samples if s[1] in selected_classes]\n",
    "\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(subset_samples)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ {len(selected_classes)} –∫–ª–∞—Å—Å–æ–≤\")\n",
    "print(f\"–í—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã: {selected_classes}\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_subset_dataset = CustomDataset(subset_samples, transform=train_transform)\n",
    "subset_loader = DataLoader(train_subset_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"–°–æ–∑–¥–∞–Ω –¥–∞—Ç–∞—Å–µ—Ç —Å {len(train_subset_dataset)} –æ–±—Ä–∞–∑—Ü–∞–º–∏\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß† –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏...\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º feature extractor (—É–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π)\n",
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "def extract_embeddings(images):\n",
    "    \"\"\"\n",
    "    –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "    images: –±–∞—Ç—á [B, 3, H, W]\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = feature_extractor(images)  # [B, 2048, 1, 1]\n",
    "        x = x.view(x.size(0), -1)      # [B, 2048]\n",
    "    return x\n",
    "\n",
    "# –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"–ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\")\n",
    "for images, labels in tqdm(subset_loader, desc=\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\"):\n",
    "    images = images.to(device)\n",
    "    emb = extract_embeddings(images)  # [B, 2048]\n",
    "    all_embeddings.append(emb.cpu())\n",
    "    all_labels.append(labels)\n",
    "\n",
    "all_embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
    "all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "print(f\"–ò–∑–≤–ª–µ—á–µ–Ω–æ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤: {all_embeddings.shape}\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–∞: {all_embeddings.shape[1]}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–æ–∫: {len(all_labels)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –®–∞–≥ 3: K-means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "\n",
    "pseudo_labels = kmeans.fit_predict(all_embeddings)\n",
    "\n",
    "print(f\"–°–æ–∑–¥–∞–Ω–æ {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\")\n",
    "print(f\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º: {Counter(pseudo_labels)}\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤\n",
    "cluster_class_mapping = {}\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_indices = np.where(pseudo_labels == cluster_id)[0]\n",
    "    cluster_classes = all_labels[cluster_indices]\n",
    "    most_common_class = Counter(cluster_classes).most_common(1)[0]\n",
    "    cluster_class_mapping[cluster_id] = most_common_class\n",
    "    print(f\"üìä –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {len(cluster_indices)} –æ–±—Ä–∞–∑—Ü–æ–≤, \"\n",
    "          f\"–¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π –∫–ª–∞—Å—Å {most_common_class[0]} ({most_common_class[1]} –æ–±—Ä–∞–∑—Ü–æ–≤)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –®–∞–≥ 4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º PCA –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–æ 2D\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "emb_2d = pca.fit_transform(all_embeddings)\n",
    "\n",
    "print(f\"PCA –æ–±—ä—è—Å–Ω—è–µ—Ç {pca.explained_variance_ratio_.sum():.3f} –¥–∏—Å–ø–µ—Ä—Å–∏–∏\")\n",
    "print(f\"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1: {pca.explained_variance_ratio_[0]:.3f}\")\n",
    "print(f\"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2: {pca.explained_variance_ratio_[1]:.3f}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, n_clusters))\n",
    "for cluster in range(n_clusters):\n",
    "    indices = np.where(pseudo_labels == cluster)[0]\n",
    "    ax1.scatter(emb_2d[indices, 0], emb_2d[indices, 1], \n",
    "               c=[colors[cluster]], label=f'Cluster {cluster}', s=20, alpha=0.7)\n",
    "\n",
    "ax1.set_title(\"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è K-means –≤ 2D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ\")\n",
    "ax1.set_xlabel(\"PC1\")\n",
    "ax1.set_ylabel(\"PC2\")\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∏—Å—Ö–æ–¥–Ω—ã–º –∫–ª–∞—Å—Å–∞–º\n",
    "class_colors = plt.cm.Set1(np.linspace(0, 1, len(selected_classes)))\n",
    "for i, class_id in enumerate(selected_classes):\n",
    "    indices = np.where(all_labels == class_id)[0]\n",
    "    ax2.scatter(emb_2d[indices, 0], emb_2d[indices, 1], \n",
    "               c=[class_colors[i]], label=f'Class {class_id}', s=20, alpha=0.7)\n",
    "\n",
    "ax2.set_title(\"–ò—Å—Ö–æ–¥–Ω—ã–µ –∫–ª–∞—Å—Å—ã –≤ 2D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ\")\n",
    "ax2.set_xlabel(\"PC1\")\n",
    "ax2.set_ylabel(\"PC2\")\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:\")\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "ari_score = adjusted_rand_score(all_labels, pseudo_labels)\n",
    "nmi_score = normalized_mutual_info_score(all_labels, pseudo_labels)\n",
    "\n",
    "print(f\"Adjusted Rand Index: {ari_score:.3f}\")\n",
    "print(f\"Normalized Mutual Information: {nmi_score:.3f}\")\n",
    "print(\"–ß–µ–º –≤—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Ç–µ–º –ª—É—á—à–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–º –∫–ª–∞—Å—Å–∞–º\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –®–∞–≥ 5: –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å —Ä–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/val –∏—Å–ø–æ–ª—å–∑—É—è –∫–ª–∞—Å—Ç–µ—Ä—ã –≤–º–µ—Å—Ç–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"–°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º...\")\n",
    "\n",
    "sss_embedding = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx_embedding, val_idx_embedding = next(sss_embedding.split(subset_samples, pseudo_labels))\n",
    "\n",
    "train_samples_embedding = [subset_samples[i] for i in train_idx_embedding]\n",
    "val_samples_embedding = [subset_samples[i] for i in val_idx_embedding]\n",
    "\n",
    "print(f\" –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —ç–º–±–µ–¥–∏–Ω–≥–∞–º:\")\n",
    "print(f\"   Train: {len(train_samples_embedding)} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
    "print(f\"   Val: {len(val_samples_embedding)} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
    "\n",
    "def analyze_embedding_split(samples, name):\n",
    "    labels = [label for _, label in samples]\n",
    "    class_counts = Counter(labels)\n",
    "    print(f\"üìä {name} - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤:\")\n",
    "    for class_id in selected_classes:\n",
    "        count = class_counts.get(class_id, 0)\n",
    "        percentage = count / len(labels) * 100\n",
    "        print(f\"   –ö–ª–∞—Å—Å {class_id}: {count} –æ–±—Ä–∞–∑—Ü–æ–≤ ({percentage:.1f}%)\")\n",
    "\n",
    "analyze_embedding_split(train_samples_embedding, \"Train (–ø–æ —ç–º–±–µ–¥–∏–Ω–≥–∞–º)\")\n",
    "analyze_embedding_split(val_samples_embedding, \"Val (–ø–æ —ç–º–±–µ–¥–∏–Ω–≥–∞–º)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 5: DataLoader —Å OpenCV –∏ Albumentations\n",
    "\n",
    "### –ó–∞—á–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenCV?\n",
    "- **–ë—ã—Å—Ç—Ä–µ–µ** —á–µ–º PIL –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π\n",
    "- **–ë–æ–ª—å—à–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π** –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\n",
    "- **–õ—É—á—à–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è** —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π Albumentations\n",
    "- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞** —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "\n",
    "####  –ß—Ç–æ —Ç–∞–∫–æ–µ Albumentations?\n",
    "- –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\n",
    "- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è\n",
    "- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ PIL, —Ç–∞–∫ –∏ OpenCV\n",
    "- –ü—Ä–æ—Å—Ç–æ–π –∏ –≥–∏–±–∫–∏–π API\n",
    "\n",
    "** –°–æ–∑–¥–∞–¥–∏–º DataLoader —Å OpenCV –∏ Albumentations:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNetAlbumentationsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    –î–∞—Ç–∞—Å–µ—Ç Tiny ImageNet —Å OpenCV + Albumentations\n",
    "    \n",
    "    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n",
    "    - –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ OpenCV\n",
    "    - –ú–æ—â–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Albumentations\n",
    "    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, split='train', augmentation=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤\n",
    "        with open(os.path.join(root_dir, 'wnids.txt'), 'r') as f:\n",
    "            self.class_names = [line.strip() for line in f.readlines()]\n",
    "        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
    "        \n",
    "        print(f\"üìä –ù–∞–π–¥–µ–Ω–æ {len(self.class_names)} –∫–ª–∞—Å—Å–æ–≤\")\n",
    "\n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        self.samples = self._make_dataset()\n",
    "        print(f\"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.samples)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è {self.split}\")\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        \"\"\"–°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        data = []\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = self._load_train_data()\n",
    "        elif self.split == 'val':\n",
    "            data = self._load_val_data()\n",
    "        elif self.split == 'test':\n",
    "            data = self._load_test_data()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split: {self.split}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _load_train_data(self):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\"\"\"\n",
    "        data = []\n",
    "        train_dir = os.path.join(self.root_dir, 'train')\n",
    "        for cls_name in os.listdir(train_dir):\n",
    "            img_dir = os.path.join(train_dir, cls_name, 'images')\n",
    "            if not os.path.isdir(img_dir):\n",
    "                continue\n",
    "            for img_name in os.listdir(img_dir):\n",
    "                img_path = os.path.join(img_dir, img_name)\n",
    "                label = self.class_to_idx[cls_name]\n",
    "                data.append((img_path, label))\n",
    "        return data\n",
    "\n",
    "    def _load_val_data(self):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\"\"\"\n",
    "        data = []\n",
    "        val_dir = os.path.join(self.root_dir, 'val')\n",
    "        img_dir = os.path.join(val_dir, 'images')\n",
    "        anno_file = os.path.join(val_dir, 'val_annotations.txt')\n",
    "\n",
    "        label_map = {}\n",
    "        with open(anno_file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                img_name, cls_name, *_ = line.strip().split('\\t')\n",
    "                label_map[img_name] = self.class_to_idx[cls_name]\n",
    "\n",
    "        for img_name in os.listdir(img_dir):\n",
    "            if img_name in label_map:\n",
    "                img_path = os.path.join(img_dir, img_name)\n",
    "                label = label_map[img_name]\n",
    "                data.append((img_path, label))\n",
    "        return data\n",
    "\n",
    "    def _load_test_data(self):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\"\"\"\n",
    "        data = []\n",
    "        test_dir = os.path.join(self.root_dir, 'test', 'images')\n",
    "        for img_name in os.listdir(test_dir):\n",
    "            img_path = os.path.join(test_dir, img_name)\n",
    "            data.append((img_path, -1))  # –Ω–µ—Ç –º–µ—Ç–æ–∫\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü –ø–æ –∏–Ω–¥–µ–∫—Å—É\"\"\"\n",
    "        img_path, label = self.samples[idx]\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR -> RGB\n",
    "\n",
    "\n",
    "        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "        if self.augmentation:\n",
    "            augmented = self.augmentation(image=img)\n",
    "            img = augmented['image']\n",
    "\n",
    "        return img, label\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π —Å –ø–æ–º–æ—â—å—é Albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º –º–æ—â–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é Albumentations\n",
    "\n",
    "train_aug = A.Compose([\n",
    "    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞\n",
    "    A.Resize(72, 72),\n",
    "    A.RandomResizedCrop(64, 64, scale=(0.8, 1.0)),\n",
    "    \n",
    "    # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    \n",
    "    # –¶–≤–µ—Ç–æ–≤—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "    \n",
    "    # –®—É–º –∏ —Ä–∞–∑–º—ã—Ç–∏–µ\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "    \n",
    "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ)\n",
    "val_aug = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset_cv = TinyImageNetAlbumentationsDataset(\n",
    "    root_dir=\"data/tiny-imagenet-200\",\n",
    "    split=\"train\",\n",
    "    augmentation=train_aug\n",
    ")\n",
    "\n",
    "val_dataset_cv = TinyImageNetAlbumentationsDataset(\n",
    "    root_dir=\"data/tiny-imagenet-200\",\n",
    "    split=\"val\",\n",
    "    augmentation=val_aug\n",
    ")\n",
    "\n",
    "train_loader_cv = DataLoader(train_dataset_cv, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader_cv = DataLoader(val_dataset_cv, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset_cv)}\")\n",
    "print(f\"Val size: {len(val_dataset_cv)}\")\n",
    "\n",
    "print(\"–¢–µ—Å—Ç–∏—Ä—É–µ–º OpenCV DataLoader...\")\n",
    "images_cv, labels_cv = next(iter(train_loader_cv))\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {images_cv.shape}\")\n",
    "print(f\"–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {images_cv.dtype}\")\n",
    "print(f\"–î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π: [{images_cv.min():.3f}, {images_cv.max():.3f}]\")\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "def denormalize_cv(img_tensor):\n",
    "    \"\"\"–î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è OpenCV –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n",
    "    img = img_tensor.permute(1, 2, 0) * std + mean\n",
    "    return img.clamp(0, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    img_vis = denormalize_cv(images_cv[i])\n",
    "    plt.imshow(img_vis)\n",
    "    plt.title(f\"Class: {labels_cv[i].item()}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"OpenCV + Albumentations DataLoader\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π ResNet –º–æ–¥–µ–ª–∏\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—Å–∫–∏ –≤ BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    –ë–∞–∑–æ–≤—ã–π –±–ª–æ–∫ ResNet —Å residual connection\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤\n",
    "        out_channels (int): –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤\n",
    "        stride (int): —à–∞–≥ —Å–≤–µ—Ä—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)\n",
    "        downsample (nn.Module): —Å–ª–æ–π –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "basic_block = BasicBlock(64, 64)\n",
    "test_input = torch.randn(2, 64, 32, 32)\n",
    "\n",
    "output = basic_block(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck –±–ª–æ–∫ ResNet (1x1 -> 3x3 -> 1x1)\n",
    "    –ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤\n",
    "        out_channels (int): –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤\n",
    "        stride (int): —à–∞–≥ —Å–≤–µ—Ä—Ç–∫–∏\n",
    "        downsample (nn.Module): —Å–ª–æ–π –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "bottleneck_block = BottleneckBlock(64, 256)\n",
    "test_input = torch.randn(2, 64, 32, 32)\n",
    "\n",
    "output = bottleneck_block(test_input)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ ResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SimpleResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleResNet18(num_classes=200)\n",
    "test_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "output = model(test_input)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\" –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}\")\n",
    "print(f\" –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ —ç–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "    \n",
    "    Args:\n",
    "        model: –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        train_loader: DataLoader —Å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "        optimizer: –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "        criterion: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å\n",
    "        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cpu/cuda)\n",
    "    \n",
    "    Returns:\n",
    "        train_loss: —Å—Ä–µ–¥–Ω—è—è –ø–æ—Ç–µ—Ä—è –∑–∞ —ç–ø–æ—Ö\n",
    "        train_acc: —Å—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –∑–∞ —ç–ø–æ—Ö\n",
    "    \"\"\"\n",
    "    model.train()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "\n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        pass\n",
    "\n",
    "    \n",
    "    return 0.0, 0.0  # TODO: –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç –ó–∞–¥–∞–Ω–∏–µ 2: –§—É–Ω–∫—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–ó–∞–≥–æ—Ç–æ–≤–∫–∞)\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "    \n",
    "    Args:\n",
    "        model: –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "        val_loader: DataLoader —Å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "        criterion: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å\n",
    "        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cpu/cuda)\n",
    "    \n",
    "    Returns:\n",
    "        val_loss: —Å—Ä–µ–¥–Ω—è—è –ø–æ—Ç–µ—Ä—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "        val_acc: —Å—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    \"\"\"\n",
    "    model.eval()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():  # –û—Ç–∫–ª—é—á–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "\n",
    "            pass\n",
    "    \n",
    "    return 0.0, 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "    \n",
    "    Args:\n",
    "        model: –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        train_loader: DataLoader —Å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "        val_loader: DataLoader —Å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "        optimizer: –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "        criterion: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å\n",
    "        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cpu/cuda)\n",
    "        num_epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "    \n",
    "    Returns:\n",
    "        history: —Å–ª–æ–≤–∞—Ä—å —Å –∏—Å—Ç–æ—Ä–∏–µ–π –æ–±—É—á–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    print(f\"–û–±—É—á–µ–Ω–∏–µ –Ω–∞ {num_epochs} —ç–ø–æ—Ö...\")\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\" –≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\" Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\" Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\" –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {val_acc:.2f}%\")\n",
    "        \n",
    "    \n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "\n",
    "    ax1.plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    ax1.plot(history['val_loss'], label='Validation Loss', color='red')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history['train_acc'], label='Train Accuracy', color='blue')\n",
    "    ax2.plot(history['val_acc'], label='Validation Accuracy', color='red')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–æ–≤\n",
    "\n",
    "selected_classes = [0, 5, 10]\n",
    "\n",
    "subset_train_samples = [s for s in train_dataset.samples if s[1] in selected_classes]\n",
    "subset_val_samples = [s for s in val_dataset.samples if s[1] in selected_classes]\n",
    "\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º {len(subset_train_samples)} train –∏ {len(subset_val_samples)} val –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π \"\n",
    "      f\"–∏–∑ {len(selected_classes)} –∫–ª–∞—Å—Å–æ–≤\")\n",
    "\n",
    "# –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "class_to_new_idx = {cls: i for i, cls in enumerate(selected_classes)}\n",
    "\n",
    "def remap_samples(samples):\n",
    "    return [(path, class_to_new_idx[label]) for path, label in samples]\n",
    "\n",
    "subset_train_samples = remap_samples(subset_train_samples)\n",
    "subset_val_samples = remap_samples(subset_val_samples)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_subset_dataset = CustomDataset(subset_train_samples, transform=train_transform)\n",
    "val_subset_dataset = CustomDataset(subset_val_samples, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_subset_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_subset_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SimpleResNet18(BasicBlock, [2, 2, 2, 2], num_classes=200)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    num_epochs=5\n",
    ")\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
